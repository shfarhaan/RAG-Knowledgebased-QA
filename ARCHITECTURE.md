# System Architecture and Design

## üèóÔ∏è Overall Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         AGENTIC RAG SYSTEM                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

                            USER INTERFACE LAYER
                                    ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ               ‚îÇ               ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇStreamlit‚îÇ  ‚îÇ  CLI Tool   ‚îÇ  ‚îÇNotebook‚îÇ
                ‚îÇ   UI    ‚îÇ  ‚îÇ  Interface  ‚îÇ  ‚îÇ Demo   ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ              ‚îÇ             ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ    APPLICATION LAYER            ‚îÇ
                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
                    ‚îÇ  ‚îÇ  Document Processor     ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îÇ  - Load documents       ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îÇ  - Chunking strategy    ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îÇ  - Metadata extraction  ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
                    ‚îÇ  ‚îÇ Embedding Manager       ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îÇ  - Azure OpenAI client  ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îÇ  - Batch processing     ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îÇ  - Caching              ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
                    ‚îÇ  ‚îÇ RAG Retriever           ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îÇ  - Query embedding      ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îÇ  - Similarity search    ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îÇ  - Ranking & filtering  ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
                    ‚îÇ  ‚îÇ Agentic RAG             ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îÇ  - Tool calling         ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îÇ  - Self-reflection      ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îÇ  - Answer generation    ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îÇ  - Multi-iteration      ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ                   ‚îÇ                   ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ External APIs  ‚îÇ  ‚îÇ  Vector DB  ‚îÇ  ‚îÇ  File       ‚îÇ
        ‚îÇ                ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ  Storage    ‚îÇ
        ‚îÇ Azure OpenAI   ‚îÇ  ‚îÇ  FAISS      ‚îÇ  ‚îÇ             ‚îÇ
        ‚îÇ Service        ‚îÇ  ‚îÇ  Index      ‚îÇ  ‚îÇ  Documents  ‚îÇ
        ‚îÇ - Embeddings   ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ  Vector     ‚îÇ
        ‚îÇ - LLM          ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ  Store      ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

```

## üîÑ Data Flow: From Document to Answer

```
STAGE 1: SETUP & INITIALIZATION
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Raw Documents
    ‚îÇ
    ‚ñº
Document Processor
‚îú‚îÄ Load files (.txt, .md, .pdf)
‚îú‚îÄ Split into chunks (with overlap)
‚îî‚îÄ Extract metadata

Chunks
    ‚îÇ
    ‚ñº
Embedding Manager
‚îî‚îÄ Convert chunks to vectors (Azure OpenAI API)

Embeddings
    ‚îÇ
    ‚ñº
FAISS Vector Store
‚îú‚îÄ Build L2 distance index
‚îú‚îÄ Save to disk
‚îî‚îÄ Metadata stored


STAGE 2: QUERY TIME - AGENTIC REASONING
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

User Query: "What is machine learning?"
    ‚îÇ
    ‚ñº
ITERATION LOOP (max 3 iterations):
    ‚îÇ
    ‚îú‚îÄ STEP 1: Tool Use - RETRIEVER
    ‚îÇ   ‚îú‚îÄ Generate query embedding
    ‚îÇ   ‚îú‚îÄ Search FAISS index
    ‚îÇ   ‚îú‚îÄ Retrieve top-K documents
    ‚îÇ   ‚îî‚îÄ Return context
    ‚îÇ
    ‚îú‚îÄ STEP 2: Self-Reflection - CRITIC
    ‚îÇ   ‚îú‚îÄ Evaluate relevance (0-100)
    ‚îÇ   ‚îú‚îÄ Evaluate coverage (0-100)
    ‚îÇ   ‚îú‚îÄ Evaluate confidence (0-100)
    ‚îÇ   ‚îú‚îÄ Identify missing aspects
    ‚îÇ   ‚îî‚îÄ Decide: Continue or refine?
    ‚îÇ
    ‚îî‚îÄ STEP 3: Query Refinement (if needed)
        ‚îú‚îÄ Analyze missing aspects
        ‚îú‚îÄ Generate new keywords
        ‚îî‚îÄ Retry STEP 1 with refined query
    ‚îÇ
    ‚ñº
STEP 4: Answer Generation - GENERATOR
    ‚îú‚îÄ Send query + context to LLM
    ‚îú‚îÄ LLM generates answer
    ‚îú‚îÄ Add source citations
    ‚îî‚îÄ Return grounded response

Grounded Answer with Citations
    ‚îÇ
    ‚ñº
User Interface
‚îî‚îÄ Display answer + metadata
```

## üéØ Agent State Machine

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   INITIAL   ‚îÇ
                    ‚îÇ   State     ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   RETRIEVING    ‚îÇ
                    ‚îÇ  (Tool: retrieve)‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   REFLECTING    ‚îÇ
                    ‚îÇ  (Critic eval)  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ               ‚îÇ               ‚îÇ
    High Quality    Medium Quality    Low Quality
    Docs Found      Docs or Need      Docs
           ‚îÇ         Refinement          ‚îÇ
           ‚îÇ          ‚îÇ                  ‚îÇ
        (Skip)   (Iterate)         (Stop/Empty)
           ‚îÇ          ‚îÇ                  ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ
                ‚îÇ                        ‚îÇ
                ‚ñº                        ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
        ‚îÇ  ANALYZING   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ              ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   GENERATING     ‚îÇ
        ‚îÇ  (LLM Answer)    ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ    COMPLETE      ‚îÇ
        ‚îÇ  (Return Result) ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üì¶ Component Details

### 1. DocumentProcessor
- **Input**: Directory with documents
- **Processing**: Load ‚Üí Chunk ‚Üí Metadata
- **Output**: List of chunks with metadata

```python
chunks = [
    {
        "content": "...",        # Chunk text
        "source": "file.txt",    # Source document
        "chunk_id": 0,           # Chunk index
        "metadata": {
            "source": "file.txt",
            "chunk_index": 0,
            "total_chunks": 50
        }
    },
    ...
]
```

### 2. EmbeddingManager
- **API**: Azure OpenAI Service
- **Model**: `text-embedding-ada-002`
- **Output**: 1536-dimensional vectors
- **Batch Processing**: Handles multiple texts efficiently

### 3. FAISSVectorStore
- **Index Type**: IndexFlatL2 (exact similarity)
- **Storage**: 
  - `faiss.index`: Vector index
  - `metadata.pkl`: Document metadata
- **Operations**:
  - Add documents and embeddings
  - Search by similarity
  - Persist to disk

### 4. RAGRetriever
- **Input**: Query string
- **Processing**:
  1. Embed query
  2. Search FAISS
  3. Filter by threshold
  4. Return ranked results
- **Output**: List of (content, similarity, source) tuples

### 5. AgenticRAG
- **States**: INITIAL ‚Üí RETRIEVING ‚Üí REFLECTING ‚Üí GENERATING ‚Üí COMPLETE
- **Tool Calls**: Retriever as callable tool
- **Critic**: Evaluates document relevance
- **Generator**: Creates grounded answers
- **Multi-iteration**: Refines queries if needed

## üîÄ Execution Flow Example

```
Query: "What is the difference between supervised and unsupervised learning?"

Step 1: Generate Query Embedding
   Input: "What is the difference between..."
   API Call: Azure OpenAI Embeddings API
   Output: [0.12, -0.45, 0.78, ...]  (1536-dim vector)

Step 2: Retrieve from FAISS
   Input: Query embedding
   Search: L2 distance
   Results: Top-5 documents
   
Step 3: Critic Evaluation
   Relevance: 85% ‚úì
   Coverage: 90% ‚úì
   Confidence: 85% ‚úì
   ‚Üí No need for refinement
   
Step 4: Generate Answer
   Input: Query + Retrieved context
   LLM: Azure OpenAI GPT-4o-mini
   Output: Well-structured answer with citations

Step 5: Return to User
   Answer: "Supervised learning uses labeled data..."
   Confidence: 85%
   Iterations: 1
   Sources: [ml_fundamentals.txt (Document 1), ...]
```

## üíæ Persistence and Caching

```
First Run:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Documents  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Embeddings   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   FAISS    ‚îÇ
‚îÇ Folder     ‚îÇ    ‚îÇ Generation   ‚îÇ    ‚îÇ   Store    ‚îÇ ‚îÄ‚îÄ‚ñ∂ Disk
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  (1-2 min)                                 ‚îÇ
                                            ‚îÇsave()
                                            ‚ñº
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ faiss.index     ‚îÇ
                                    ‚îÇ metadata.pkl    ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò


Subsequent Runs:
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ faiss.index     ‚îÇ
                                    ‚îÇ metadata.pkl    ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚îÇload()
                                             ‚ñº
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ   FAISS Store   ‚îÇ
                                    ‚îÇ   (in memory)   ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚îÇ
                                    Ready for queries!
                                    (instant access)
```

## üìä Performance Characteristics

| Operation | Time | Notes |
|-----------|------|-------|
| Document Processing | ~1s per document | Depends on size |
| Embedding Generation | ~2s per 50 chunks | API call limited |
| Vector Store Build | ~5s for 1000 chunks | FAISS indexing |
| Query Embedding | ~200ms | Single API call |
| Similarity Search | ~50ms | FAISS L2 distance |
| Critic Evaluation | ~3-5s | Additional LLM call |
| Answer Generation | ~5-10s | LLM inference |
| **Total Latency** | **~8-20s** | Per query (1 iteration) |

## üéì Learning Components

### Document Chunking
- Fixed-size chunks: 1000 characters
- Overlapping windows: 200 character overlap
- Sentence-aware breaking: Try to break at periods/newlines

### Embedding Quality
- Dense representations: 1536 dimensions (text-embedding-ada-002)
- Semantic meaning: Understands context
- Query-document alignment: Cosine/L2 similarity

### Retrieval Ranking
- L2 Distance: `distance = sqrt(sum((a-b)^2))`
- Similarity: `similarity = 1 / (1 + distance)`
- Threshold: Only return if similarity > 0.3

### Answer Grounding
- Retrieved documents kept in context
- LLM instructed to cite sources
- Explicit acknowledgment of missing info
- Minimized hallucination

## üîê Safety and Hallucination Prevention

1. **Retrieval Grounding**: Answers based on real documents
2. **Threshold Filtering**: Ignore low-relevance results
3. **Explicit Uncertainty**: State when unsure
4. **Source Attribution**: Always cite sources
5. **Critic Evaluation**: Validate document quality
6. **Iterative Refinement**: Multiple attempts if needed
7. **Confidence Scoring**: Show how confident system is
